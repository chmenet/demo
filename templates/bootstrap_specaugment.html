

<html>
  <head>
    <meta charset="UTF-8">
    <title>Augmented voice conversion</title>
    <link rel="stylesheet" href="../../stylesheet.css">
    <link rel="shortcut icon" href="../../images/taco.png">
  </head>
  <body>
    <article>
      <header>
        <h1>Augmented voice conversion</h1>
      </header>
    </article>

    <p><b>Paper:</b> <a href="https://arxiv.org/abs/">arXiv</a></p>

    <p><b>Authors:</b> authors name </p>

    <div><b>Abstract:</b>
      Insert abstract
    </div>

    <p> <a href="../../index.html">Click here for more from the Tacotron team.</a></p>

    <div>
      <b>Note:</b>
      <span style="background-color: #EEE">To obtain the best quality, we strongly recommend readers to listen to the audio samples with headphones.</span>
    </div>

    <p class="toc_title">Contents</p>
    <div id="toc_container">
      <ul>
	<li><a href="#normalization">Section 1: Voice normalization</a></li>
	<li><a href="#normalization-impaired">Section 2: Normalization of hearing-impaired speech</a></li>
	<li><a href="#separation">Section 3: Speech separation</a></li>
	<li><a href="#acknowledgements">Acknowledgements</a></li>
      </ul>
    </div>

    <div>
      <a name="normalization"><h2>Section 1: Voice normalization</h2></a>
      <div>
        In this section, we present examples of running Parrotron to directly normalize speech to a TTS voice.
	Examples are from the <a href="https://datashare.is.ed.ac.uk/handle/10283/2651">VCTK corpus</a> licensed under the <a href="https://opendatacommons.org/licenses/by/1.0/">Open Data Commons Attribution License (ODC-By) v1.0</a>.
	(Griffin-Lim Vocoder).
      </div>

      </br>
      <table>
        <tbody>
        <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
        </tr>

        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/01_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/01_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/02_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/02_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/03_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/03_norm_output.wav"></audio></td>
        </tr>

        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/04_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/04_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/05_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/05_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/06_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/06_norm_output.wav"></audio></td>
        </tr>

        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/07_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/07_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/08_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/08_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/09_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/09_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/10_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/10_norm_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/norm_vctk/11_norm_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/norm_vctk/11_norm_output.wav"></audio></td>
        </tr>
        </tbody>
      </table>
    </div>

    <br/>
    <h3>Extra</h3>
    <div>
      Examples of running the normalization model, which is trained on American English speech, on non-English inputs.
      <!--TODO(biadsy): add more.-->
    </div>

      </br>
      <table>
        <tbody>
          <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
          </tr>
          <tr>
            <td><audio controls=""><source src="audio/extra/arabic_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/extra/arabic_parrotron.wav"></audio></td>
          </tr>
          <tr>
            <td><audio controls=""><source src="audio/extra/do_rai_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/extra/do_rai_parrotron.wav"></audio></td>
          </tr>
        </tbody>
      </table>


    <p/>
    <br/>
    <div>
      <a name="normalization-impaired"><h2>Section 2: Augmentation </h2></a>

      <div>
        In this section, we present examples of running Parrotron to convert atypical speech from a deaf speaker to fluent speech. The model is same as the normalization model above, but trained on a male target speaker voice. We include examples before and after adapting the model on 13.5 hours of speech from a deaf speaker.
      </div>
      &nbsp;

      <h3>After adaptation</h3>
      </br>
      <table>
        <tbody>
          <tr>
            <td align="center"> Input </td>
            <td align="center"> Output </td>
            <td align="center"> &nbsp;&nbsp; </td>
            <td align="center"> Reference Transcript </td>
          </tr>
          <tr>
            <td><audio controls=""><source src="audio/deaf/00_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/00_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Here is some information about Oklahoma</i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/01_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/01_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>When do the girls get to the party?</i></td>
          </tr>
          <tr>
            <td><audio controls=""><source src="audio/deaf/02_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/02_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>You can use your regular name outside the game.</i></td>
          </tr>
          <tr>
            <td><audio controls=""><source src="audio/deaf/03_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/03_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Here are listings for Clarks Village near Ann Arbor.</i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/04_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/04_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Maybe something happened to them.</i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/05_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/05_parrotron_adapted.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Amber India restaurant is open until two A M tomorrow.</i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/08_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/08_output.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Here are your directions. </i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/09_input.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/09_output.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>OK, three hours 45 minutes.</i></td>
          </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/01_input_testset2.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/01_output_testset2.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>What is the weather tomorrow in Mountain View?</i></td>
          </tr>

           <tr>
            <td><audio controls=""><source src="audio/deaf/04_input_testset2.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/04_output_testset2.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>I want to see if Parrotron would work for other languages.</i></td>
           </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/05_input_testset2.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/05_output_testset2.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>Salam [Arabic for Peace]</i></td>
           </tr>

          <tr>
            <td><audio controls=""><source src="audio/deaf/09_input_testset2.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/09_output_testset2.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>I like Fadi.</i></td>
          </tr>

           <tr>
            <td><audio controls=""><source src="audio/deaf/06_input_testset2.wav"></audio></td>
            <td><audio controls=""><source src="audio/deaf/06_output_testset2.wav"></audio></td>
            <td>&nbsp;&nbsp;</td>
            <td><i>I'm hungry.</i></td>
          </tr>

        </tbody>
      </table>
    </div>
    <br/>

    <h3>Before adaptation</h3>

    <table>
      <tbody>
        <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/deaf/00_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/deaf/00_parrotron_unadapted.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/deaf/01_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/deaf/01_parrotron_unadapted.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/deaf/02_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/deaf/02_parrotron_unadapted.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/deaf/03_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/deaf/03_parrotron_unadapted.wav"></audio></td>
        </tr>
      </tbody>
    </table>

    <p/>
    <br/>
    <div>
      <a name="separation"><h2>Section 3: Augmentation hyperparameter test</h2></a>
      <div>
        In this section, we present examples of training Parrotron to perform a speech separation task. We train it to identify and extract the loudest speaker in a mix of overlapping 8 speakers.
	Examples are from the <a href="https://datashare.is.ed.ac.uk/handle/10283/2651">VCTK corpus</a> licensed under the <a href="https://opendatacommons.org/licenses/by/1.0/">Open Data Commons Attribution License (ODC-By) v1.0</a>.
        (Griffin-Lim Vocoder).
      </div>

      </br>
      <table>
        <tbody>
        <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_output.wav"></audio></td>
        </tr>
        </tbody>
      </table>
    </div>

    <p/>


    <p/>
    <br/>
    <div>
      <a name="separation"><h2>Section 4: Augmentation</h2></a>
      <div>
        In this section, we present examples of training Parrotron to perform a speech separation task. We train it to identify and extract the loudest speaker in a mix of overlapping 8 speakers.
	Examples are from the <a href="https://datashare.is.ed.ac.uk/handle/10283/2651">VCTK corpus</a> licensed under the <a href="https://opendatacommons.org/licenses/by/1.0/">Open Data Commons Attribution License (ODC-By) v1.0</a>.
        (Griffin-Lim Vocoder).
      </div>

      </br>
      <table>
        <tbody>
        <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_output.wav"></audio></td>
        </tr>
        </tbody>
      </table>
    </div>

    <p/>


    <p/>
    <br/>
    <div>
      <a name="separation"><h2>Section 5: VCTK dataset training</h2></a>
      <div>
        In this section, we present examples of training Parrotron to perform a speech separation task. We train it to identify and extract the loudest speaker in a mix of overlapping 8 speakers.
	Examples are from the <a href="https://datashare.is.ed.ac.uk/handle/10283/2651">VCTK corpus</a> licensed under the <a href="https://opendatacommons.org/licenses/by/1.0/">Open Data Commons Attribution License (ODC-By) v1.0</a>.
        (Griffin-Lim Vocoder).
      </div>

      </br>
      <table>
        <tbody>
        <tr>
          <td align="center"> Input </td>
          <td align="center"> Output </td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/00_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/01_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/02_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/03_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/04_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/05_separate_output.wav"></audio></td>
        </tr>
        <tr>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_input.wav"></audio></td>
          <td><audio controls=""><source src="audio/separation_vctk/06_separate_output.wav"></audio></td>
        </tr>
        </tbody>
      </table>
    </div>

    <p/>

    </br>
    <a name="acknowledgements"><h2>Acknowledgments</h2></a>
    <div>
      We thank Françoise Beaufays, Michael Brenner, Diamantino Caseiro, Zhifeng Chen, Mohamed Elfeky, Patrick Nguyen, Bhuvana Ramabhadran, Andrew Rosenberg, Jason Pelecanos, Johan Schalkwyk, Yonghui Wu, and Zelin Wu for useful feedback.
    </div>


</body></html>
